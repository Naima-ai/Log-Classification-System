# -*- coding: utf-8 -*-
"""Log Classification System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WjButNwOfWVvdqOfy_j11xDYYzj8WbeQ
"""
import pandas as pd
import numpy as np

df= pd.read_csv('synthetic_logs.csv')

df.head()

df.shape

df.drop('complexity',axis=1,inplace=True)

df['source'].unique()

"""DBSCAN clustering for finding patterns in log messages"""

from sentence_transformers import SentenceTransformer
from sklearn.cluster import DBSCAN

model=SentenceTransformer('all-MiniLM-L6-v2') #model needs less space

embeddings=model.encode(df['log_message'].to_list())

dbscan=DBSCAN(eps=0.2,min_samples=1,metric='cosine')
clusters=dbscan.fit_predict(embeddings)

df['cluster']=clusters

df.head()

df['cluster'].unique()

import re
def classify_with_regex(log_message):
    regex_patterns = {
        r"User User\d+ logged (in|out).": "User Action",
        r"Backup (started|ended) at .*": "System Notification",
        r"Backup completed successfully.": "System Notification",
        r"System updated to version .*": "System Notification",
        r"File .* uploaded successfully by user .*": "System Notification",
        r"Disk cleanup completed successfully.": "System Notification",
        r"System reboot initiated by user .*": "System Notification",
        r"Account with ID .* created by .*": "User Action"
    }
    for pattern, label in regex_patterns.items():
        if re.search(pattern, log_message):
            return label
    return None

classify_with_regex("User User345 logged in.")

classify_with_regex("System reboot initiated by user User179.")

df['regex_label']=df['log_message'].apply(classify_with_regex)

df[df['regex_label'].notnull()].shape

df[df['regex_label'].isnull()]

df_non_regex=df[df['regex_label'].isnull()].copy()

df_non_regex.shape

"""Now check the none labels with wither LLM or BERT

In the dataset, we have workflow and deprecation warnings samples less than 5. so we just classify them with lmm. and create a separate df without their soursce. which is legacy crm
"""

df_filtered=df_non_regex[df_non_regex['source']!='LegacyCRM']

df_filtered['source'].unique()

"""creating embeddings using the same BERT model"""

filtered_embeddings=model.encode(df_filtered['log_message'].to_list())

"""model building with logistic regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X=filtered_embeddings
y=df_filtered['target_label']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

clf=LogisticRegression(max_iter=1000)
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)
report=classification_report(y_test,y_pred)
print(report)

import joblib
joblib.dump(clf,'log_classifier.joblib')

